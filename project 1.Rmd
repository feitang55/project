---
title: "Practical-Machine-Learning-Week-4-Assignment"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(caret)
```


Import training and testing sets
```{r cars}
training = read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"))
testing = read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"))
```
check dataset contents
```{r}
names(training)
names(testing)#do not have classe variable
```

check how 'classe' is ditributed in the training set
```{r}
unique(training[c("classe")])
table(training$classe)
```

!!!Data cleaning!!!
1. remove variables with high proportion of NA
 - check proportion of NA of each variable
```{r}
colMeans(is.na(training))
```

- remove variables with 90%+ missingness
```{r}
colna<-sapply(training, function(x) mean(is.na(x))) > 0.9
training_clean <-training[, colna=='FALSE']
testing_clean<-testing[,colna=='FALSE']
```

- check proportion of NA of each variable after removal
```{r}
colMeans(is.na(training_clean))
```

2. remove variables that are not relevant:X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, num_window
```{r}
training_clean=subset(training_clean, select = -c(X, user_name, raw_timestamp_part_1, 
                                                 raw_timestamp_part_2, cvtd_timestamp, new_window, num_window))
testing_clean=subset(testing_clean, select = -c(X, user_name, raw_timestamp_part_1, 
                                                  raw_timestamp_part_2, cvtd_timestamp, new_window, num_window))
```
check variables after removal
```{r}
dim(training_clean)
dim(testing_clean)
```
3. remove variables with near zero variance - they are not useful in the prediction
```{r}
colnearzero<-nearZeroVar(training_clean)
training_clean=training_clean[,-colnearzero]
testing_clean=testing_clean[,-colnearzero]
```
check variables after removal
```{r}
dim(training_clean)
dim(testing_clean)
```
!!!Data partition!!!

Create training and testing data from the original training dataset,
```{r}
inTrain = createDataPartition(training_clean$classe, p = 3/4)[[1]]
training_new = training_clean[ inTrain,]
testing_new = training_clean[-inTrain,]
dim(training_new)
dim(testing_new)
```

!!!Data modeling!!!

Model 1. Random Forest (RF)
```{r}
modfitRF<-train(classe~.,  data=training_new, method="rf" , ntree=100)
predRF <- predict(modfitRF, testing_new)
confusionMatrix(predRF, factor(testing_new$classe))
#Accuracy is 99% across all 5 classes
```
Visualize the accuracy results by class
```{r}
accuracyRF <- confusionMatrix(predRF, factor(testing_new$classe), dnn = c("Prediction", "Reference"))
ggplot(as.data.frame(accuracyRF$table), aes(Prediction,sort(Reference,decreasing = T), fill= Freq)) +
  geom_tile() + geom_text(aes(label=Freq)) +
  scale_fill_gradient(low="white", high="#33C7FF") +
  labs(x = "Reference",y = "Prediction") +
  scale_x_discrete(labels=c("Class_A","Class_C","Class_C","Class_D","Class_E" )) +
  scale_y_discrete(labels=c("Class_E","Class_D","Class_C","Class_B","Class_A"))
```
Model 2. Gradient Boosting Machine (GBM)
```{r}
modfitGBM<-train(classe~.,  data=training_new, method="gbm")
predGBM <- predict(modfitGBM, testing_new)
confusionMatrix(predGBM, factor(testing_new$classe))
#Accuracy ranges from 96% - 99% across 5 classes
```
Visualize the accuracy results by class
```{r}
accuracyGBM <- confusionMatrix(predGBM, factor(testing_new$classe), dnn = c("Prediction", "Reference"))
ggplot(as.data.frame(accuracyGBM$table), aes(Prediction,sort(Reference,decreasing = T), fill= Freq)) +
  geom_tile() + geom_text(aes(label=Freq)) +
  scale_fill_gradient(low="white", high="#33C7FF") +
  labs(x = "Reference",y = "Prediction") +
  scale_x_discrete(labels=c("Class_A","Class_C","Class_C","Class_D","Class_E" )) +
  scale_y_discrete(labels=c("Class_E","Class_D","Class_C","Class_B","Class_A"))
```

Model 3. Linear Discriminant Analysis (LDA)
```{r}
modfitLDA<-train(classe~.,  data=training_new, method="lda")
predLDA <- predict(modfitLDA, testing_new)
confusionMatrix(predLDA, factor(testing_new$classe))
#Accuracy ranges from 77% - 86% across 5 classes
```
Visualize the accuracy results by class
```{r}
accuracyLDA <- confusionMatrix(predLDA, factor(testing_new$classe), dnn = c("Prediction", "Reference"))
ggplot(as.data.frame(accuracyLDA$table), aes(Prediction,sort(Reference,decreasing = T), fill= Freq)) +
  geom_tile() + geom_text(aes(label=Freq)) +
  scale_fill_gradient(low="white", high="#33C7FF") +
  labs(x = "Reference",y = "Prediction") +
  scale_x_discrete(labels=c("Class_A","Class_C","Class_C","Class_D","Class_E" )) +
  scale_y_discrete(labels=c("Class_E","Class_D","Class_C","Class_B","Class_A"))
```
!!!Random forest is the most accurate model!!!
Apply the random forest model to predict the original testing set
```{r}
predRF <- predict(modfitRF, testing_clean)
predRF
```


